# distributed: true # 是否使用分布式训练
# gpu_ids: [2, 3] # 可用的gpu id
# world_size: 2 # gpu数量

distributed: false # 是否使用分布式训练
gpu_ids: [2] # 可用的gpu id


seed: 0 # 随机数种子
save_dir: saved # 保存的根路径
num_epochs: 1000 # 最大epoch数
num_log_steps: 10 # 每多少个step输出log, 0 means no output
num_valid_epochs: 1 # 每多少个epoch运行valid
scheduler_interval: step
batch_size: 4096
load_saved_model: false

cell_types: &cell_types [K562, HepG2, SK-N-SH, 'A549', 'HCT116']
# assays: &assays [DNase, H3K4me3, H3K27ac, CTCF]

train_dataset:
  type: &type SeqDataset
  args: &args
    data_path: ./data/GosaiMPRA/GosaiMPRA_my_processed_data_len200_norm.csv
    apply_filter: true
    filter_column: chr
    filter_in_list: [chr3, chr4, chr5, chr6, chr7, chr8, chr9, chr10, chr11, chr12,
      chr13, chr14, chr15, chr16, chr17, chr18, chr19, chr20, chr21, chr22]
    seq_column: seq
    label_column: *cell_types
    # cell_types: *cell_types
    # assays: *assays

valid_dataset:
  type: *type
  args:
    <<: *args
    filter_in_list: [chr1]

test_dataset:
  type: *type
  args:
    <<: *args
    apply_filter: false


model:
    type: DenseNet
    args:


        input_length: 200
        input_channels: 4
        output_dim: 5
        first_cnn_channels: 128
        growth_rate: 64
        dense_block_config: [2,2,2,2,2,2]
        dropout_rate: 0.2

        linear_channels_list: [256]


        # input_seq_length: 200
        # input_feature_shape: null
        # output_dim: 5
        # sigmoid: false
        # squeeze: true

        # conv_channels_list: [256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256,
        # 256, 256, 256, 256, 256, 256]
        # conv_kernel_size_list: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
        # conv_padding_list: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
        # pool_kernel_size_list: [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2]
        # conv_dropout_rate: 0.1
        # global_average_pooling: false
        
        # num_trans_blocks: 3
        # trans_d_embed: 256
        # trans_n_heads: 4
        # trans_d_mlp: 256
        # trans_dropout_rate: 0.1
        
        # linear_channels_list: [256]
        # linear_dropout_rate: 0.5





optimizer:
  type: AdamW
  args:
    lr: 1.0e-3
    weight_decay: 1.0e-4
  transformer_args:
    lr: 1.0e-4
    weight_decay: 1.0e-4


# lr_scheduler:
#   type: CosineAnnealingWarmRestarts
#   args:
#     T_0: 20

lr_scheduler:
  type: WarmupCosineAnnealingWarmRestarts
  args:
    warmup_epochs: 10
    T_0: 10
    T_mult: 2

loss_func:
  type: MyMSELoss

metric_funcs:
- type: MyMSELoss
- type: Pearson
- type: Spearman

early_stopper:
  type: EarlyStopping
  args:
    monitor: Pearson
    patience: 40
    delta: 0
    mode: max
    verbose: true

logger:
  version: 1
  disable_existing_loggers: false
  formatters:
    simple:
      format: '%(message)s'
    complex:
      format: '%(asctime)s - %(levelname)s - %(message)s'
  handlers:
    console_handler:
      class: logging.StreamHandler
      level: INFO
      formatter: complex
      stream: ext://sys.stdout
    info_file_handler:
      class: logging.handlers.RotatingFileHandler
      level: INFO
      formatter: complex
      filename: info.log
      maxBytes: 10485760
      backupCount: 10
      encoding: utf8
    debug_file_handler:
      class: logging.handlers.RotatingFileHandler
      level: DEBUG
      formatter: complex
      filename: debug.log
      maxBytes: 10485760
      backupCount: 10
      encoding: utf8
  root:
    level: DEBUG
    handlers:
    - console_handler
    - info_file_handler
    - debug_file_handler
